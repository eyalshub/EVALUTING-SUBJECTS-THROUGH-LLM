{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "jSmxSK-R6YrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n",
        "!pip install bertopic\n",
        "!pip install sentence-transformers faiss-cpu torch transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p8mdd2f-aKT",
        "outputId": "1057b870-116e-4389-de4b-ec3495aecef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.6.0)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (3.3.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.5.7)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.47.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (11.1.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.12.14)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "-vFLA5xF6c8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import faiss\n",
        "import numpy as np\n",
        "from groq import Groq\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import pipeline\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n"
      ],
      "metadata": {
        "id": "wnUZac4V-ZxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6H8BzgI-tpA",
        "outputId": "f7ebae17-fae6-463b-b0b6-7a776d40180f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data class to store LLM responses with enhanced fields"
      ],
      "metadata": {
        "id": "VPqvxIuG6u_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class LLMResponse:\n",
        "    content: str\n",
        "    score: float = None\n",
        "    topic: str = None\n",
        "    confidence: float = None\n",
        "    error: str = None\n",
        "    metadata: Dict[str, Any] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.metadata is None:\n",
        "            self.metadata = {}\n"
      ],
      "metadata": {
        "id": "QugALF4f-wc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data class to store document information"
      ],
      "metadata": {
        "id": "WPOSit7m62kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Document:\n",
        "    content: str\n",
        "    embedding: np.ndarray = None\n",
        "    metadata: Dict[str, Any] = None"
      ],
      "metadata": {
        "id": "9PyRJGcmBgXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval-Augmented Generation (RAG) system, combining a neural embedding model with a vector similarity search engine to manage and retrieve relevant documents."
      ],
      "metadata": {
        "id": "tNj5Lszk6-eK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGSystem:\n",
        "    def __init__(self, embedding_model=\"all-MiniLM-L6-v2\"):\n",
        "      \"\"\"\n",
        "      Initializes the RAG system:\n",
        "        Loads the specified embedding model.\n",
        "        Creates an empty document store and sets the FAISS index to None.\n",
        "      \"\"\"\n",
        "        self.embedding_model = SentenceTransformer(embedding_model)\n",
        "        self.document_store = []\n",
        "        self.index = None\n",
        "\n",
        "    def add_documents(self, documents: List[str]):\n",
        "      \"\"\"\n",
        "      Adds documents to the system and prepares them for retrieval\n",
        "      Converts each document into a vector embedding using the SentenceTransformer model.\n",
        "      Each document is wrapped in a Document object containing:\n",
        "          content: The text of the document.\n",
        "          embedding: The corresponding embedding (as a NumPy array).\n",
        "      These objects are appended to document_store.\n",
        "      \"\"\"\n",
        "        embeddings = self.embedding_model.encode(documents, convert_to_tensor=True)\n",
        "        for doc, emb in zip(documents, embeddings):\n",
        "            self.document_store.append(Document(\n",
        "                content=doc,\n",
        "                embedding=emb.numpy()\n",
        "            ))\n",
        "        self._update_index()\n",
        "\n",
        "    def _update_index(self):\n",
        "      \"\"\"\n",
        "      Updates the FAISS index with embeddings from all stored documents\n",
        "      \"\"\"\n",
        "        embeddings = np.vstack([doc.embedding for doc in self.document_store])\n",
        "        dimension = embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dimension)\n",
        "        self.index.add(embeddings.astype('float32'))\n",
        "\n",
        "    def retrieve_relevant_docs(self, query: str, k: int = 3):\n",
        "      \"\"\"\n",
        "      Retrieves the top-k documents most relevant to a given query\n",
        "      \"\"\"\n",
        "        query_embedding = self.embedding_model.encode([query])[0]\n",
        "        D, I = self.index.search(query_embedding.reshape(1, -1).astype('float32'), k)\n",
        "        return [self.document_store[i] for i in I[0]]\n"
      ],
      "metadata": {
        "id": "DMmSrPxZ-2cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract pattern from text with fallback"
      ],
      "metadata": {
        "id": "hw6EYHOpFMfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_pattern_safely(pattern, text, default=None):\n",
        "    if not text:\n",
        "        return default\n",
        "    try:\n",
        "        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "    except Exception:\n",
        "        pass\n",
        "    return default\n"
      ],
      "metadata": {
        "id": "_Y__alh8ABQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean and standardize topic string"
      ],
      "metadata": {
        "id": "SbZEHL9zFe6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_topic(topic):\n",
        "    if not topic:\n",
        "        return None\n",
        "\n",
        "    topic = re.sub(r'^\\d+\\.\\s*', '', topic)\n",
        "    topic = re.sub(r'^-\\s*', '', topic)\n",
        "    topic = re.sub(r'^\\(|\\)$', '', topic)\n",
        "    topic = re.sub(r'\\b\\d+millisecond\\b', '', topic)\n",
        "    topic = re.sub(r'\\s+and\\s+', ' & ', topic)\n",
        "    topic = ' '.join(topic.split())\n",
        "    topic = topic.strip()\n",
        "\n",
        "    if len(topic) < 3:\n",
        "        return None\n",
        "\n",
        "    return topic"
      ],
      "metadata": {
        "id": "2RbORsM9FZR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing with cleaning and standardization"
      ],
      "metadata": {
        "id": "OKzBIsljFoDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    custom_stops = {'would', 'could', 'should', 'said', 'like', 'also'}\n",
        "    stop_words.update(custom_stops)\n",
        "\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if (token not in stop_words and\n",
        "            len(token) > 2 and\n",
        "            not token.isnumeric() and\n",
        "            not all(c in '0123456789.-' for c in token)):\n",
        "\n",
        "            if token.isupper() and len(token) <= 5:\n",
        "                filtered_tokens.append(token)\n",
        "            else:\n",
        "                filtered_tokens.append(token.lower())\n",
        "\n",
        "    cleaned_text = \" \".join(filtered_tokens)\n",
        "    return cleaned_text if cleaned_text.strip() else \"placeholder\""
      ],
      "metadata": {
        "id": "DLfNDOWPFnVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document preprocessing for topic modeling"
      ],
      "metadata": {
        "id": "cKOcPsKVF07O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_documents(documents):\n",
        "    processed_docs = []\n",
        "    for doc in documents:\n",
        "        try:\n",
        "            if isinstance(doc, str):\n",
        "                # Basic cleaning\n",
        "                doc = doc.lower()\n",
        "                doc = re.sub(r'\\s+', ' ', doc)\n",
        "                doc = re.sub(r'[^\\w\\s-]', '', doc)\n",
        "\n",
        "                # Tokenize\n",
        "                tokens = word_tokenize(doc)\n",
        "                stop_words = set(stopwords.words('english'))\n",
        "                custom_stops = {'would', 'could', 'should', 'said', 'like', 'also'}\n",
        "                stop_words.update(custom_stops)\n",
        "\n",
        "                # Filter tokens\n",
        "                filtered_tokens = []\n",
        "                for token in tokens:\n",
        "                    if (token not in stop_words and\n",
        "                        len(token) > 2 and\n",
        "                        not token.isnumeric() and\n",
        "                        not all(c in '0123456789.-' for c in token)):\n",
        "                        filtered_tokens.append(token.lower())\n",
        "\n",
        "                if filtered_tokens:  # Only append if we have tokens\n",
        "                    processed_docs.append(filtered_tokens)\n",
        "                else:\n",
        "                    processed_docs.append(['placeholder'])  # Add placeholder if no tokens\n",
        "            else:\n",
        "                processed_docs.append(['placeholder'])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preprocessing document: {e}\")\n",
        "            processed_docs.append(['placeholder'])  # Add placeholder on error\n",
        "\n",
        "    return processed_docs\n"
      ],
      "metadata": {
        "id": "69lyAZyEFz0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class for advanced processing of technical text using a large language model.\n",
        "\n",
        "Summarizing technical content.\n",
        "\n",
        "Classifying topics and extracting technical features.\n",
        "\n",
        "Grading groups of documents for coherence and distinctiveness."
      ],
      "metadata": {
        "id": "cVpd8l_mDm-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedLLMProcessor:\n",
        "    def __init__(self, api_key: str, model: str = \"llama-3.2-3b-preview\"):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "        self.model = model\n",
        "\n",
        "        self.prompts = {\n",
        "            \"summarize\": \"\"\"You are a technical document analyzer specializing in extracting key information from texts.\n",
        "\n",
        "TEXT TO ANALYZE:\n",
        "{text}\n",
        "\n",
        "RELEVANT CONTEXT:\n",
        "{context}\n",
        "\n",
        "Provide your analysis in this EXACT format:\n",
        "MAIN_TOPIC: [primary technical/scientific field]\n",
        "KEY_TERMS: [list only the most relevant technical terms, comma-separated]\n",
        "SUMMARY: [2-3 concise, technical sentences capturing the essence]\"\"\",\n",
        "\n",
        "            \"topic\": \"\"\"You are an expert topic classifier focusing on technical and academic content.\n",
        "\n",
        "Document for classification:\n",
        "{text}\n",
        "\n",
        "Analyze this document following these steps:\n",
        "1. Identify primary technical domain\n",
        "2. Extract key technical terminology\n",
        "3. Recognize methodological approaches\n",
        "4. Note any cross-domain elements\n",
        "\n",
        "Provide classification in this EXACT format:\n",
        "PRIMARY_TOPIC: [single specific technical field]\n",
        "SUBTOPICS: [3-4 related technical areas]\n",
        "TECHNICAL_INDICATORS: [key technical terms that influenced classification]\n",
        "CROSS_DOMAIN_ELEMENTS: [any interdisciplinary aspects]\n",
        "CONFIDENCE: [0-1 score with brief justification]\"\"\",\n",
        "\n",
        "            \"grade\": \"\"\"You are a specialized content coherence evaluator.\n",
        "\n",
        "TARGET GROUP:\n",
        "{documents}\n",
        "\n",
        "COMPARISON GROUPS:\n",
        "{other_groups}\n",
        "\n",
        "Evaluation Criteria:\n",
        "1. INTERNAL COHERENCE (50%)\n",
        "- How consistently do the documents align in topic and terminology?\n",
        "- Do they share a common technical vocabulary?\n",
        "- Is there thematic continuity?\n",
        "\n",
        "2. EXTERNAL DISTINCTIVENESS (50%)\n",
        "- How clearly separated is this group from others?\n",
        "- Are there unique technical markers?\n",
        "- Is there minimal topic overlap with other groups?\n",
        "\n",
        "Provide your evaluation in this EXACT format:\n",
        "COHERENCE_SCORE: [1-10]\n",
        "DISTINCTIVENESS_SCORE: [1-10]\n",
        "FINAL_SCORE: [average of above, rounded to nearest whole number]\n",
        "STRONG_POINTS: [bullet list of group's strongest cohesion markers]\n",
        "DISTINGUISHING_FEATURES: [key elements that separate this group]\"\"\"\n",
        "        }\n",
        "\n",
        "    def process_text(self, text: str, task: str, additional_context: Dict = None) -> LLMResponse:\n",
        "        try:\n",
        "            prompt_template = self.prompts.get(task)\n",
        "            if not prompt_template:\n",
        "                raise ValueError(f\"Unknown task: {task}\")\n",
        "\n",
        "            # Initialize default context values\n",
        "            context = {\n",
        "                \"text\": text,\n",
        "                \"context\": \"\",  # Default empty context\n",
        "                \"documents\": \"\",  # Default empty documents\n",
        "                \"other_groups\": \"\"  # Default empty other_groups\n",
        "            }\n",
        "\n",
        "            # Update with any additional context provided\n",
        "            if additional_context:\n",
        "                context.update(additional_context)\n",
        "\n",
        "            # Format the prompt with the context\n",
        "            prompt = prompt_template.format(**context)\n",
        "\n",
        "            # Process with LLM\n",
        "            if task == \"summarize\":\n",
        "                completion = self.client.chat.completions.create(\n",
        "                    model=self.model,\n",
        "                    messages=[\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": \"You are a specialized technical content analysis system.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": prompt\n",
        "                        }\n",
        "                    ],\n",
        "                    temperature=0.3,\n",
        "                    max_tokens=500,\n",
        "                    stream=True\n",
        "                )\n",
        "\n",
        "                response = \"\"\n",
        "                for chunk in completion:\n",
        "                    response += chunk.choices[0].delta.content or \"\"\n",
        "\n",
        "                if not all(section in response for section in [\"MAIN_TOPIC:\", \"KEY_TERMS:\", \"SUMMARY:\"]):\n",
        "                    return LLMResponse(content=text[:200] + \"...\")\n",
        "\n",
        "            else:  # For topic and grade tasks\n",
        "                completion = self.client.chat.completions.create(\n",
        "                    model=self.model,\n",
        "                    messages=[\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": \"You are a specialized technical content analysis system.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": prompt\n",
        "                        }\n",
        "                    ],\n",
        "                    temperature=0.5,\n",
        "                    max_tokens=500,\n",
        "                    stream=False\n",
        "                )\n",
        "\n",
        "                response = completion.choices[0].message.content.strip()\n",
        "\n",
        "            # Process responses based on task\n",
        "            if task == \"grade\":\n",
        "                score = self._extract_score_from_response(response)\n",
        "                coherence = self._calculate_group_coherence([text])\n",
        "                return LLMResponse(\n",
        "                    content=response,\n",
        "                    score=score,\n",
        "                    metadata={\"coherence\": coherence}\n",
        "                )\n",
        "\n",
        "            elif task == \"topic\":\n",
        "                topic_info = self._extract_topic_info(response)\n",
        "                return LLMResponse(\n",
        "                    content=response,\n",
        "                    topic=topic_info[\"primary_topic\"],\n",
        "                    confidence=topic_info[\"confidence\"],\n",
        "                    metadata=topic_info\n",
        "                )\n",
        "\n",
        "            return LLMResponse(content=response)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in processing {task}: {str(e)}\")\n",
        "            return LLMResponse(content=\"\", error=str(e))\n",
        "\n",
        "    def _extract_score_from_response(self, response_text):\n",
        "        \"\"\"Extract numerical score from LLM response with fallback options\"\"\"\n",
        "        try:\n",
        "            # First try to get explicit scores\n",
        "            coherence_match = re.search(r'COHERENCE_SCORE:\\s*(\\d+)', response_text)\n",
        "            distinctiveness_match = re.search(r'DISTINCTIVENESS_SCORE:\\s*(\\d+)', response_text)\n",
        "            final_match = re.search(r'FINAL_SCORE:\\s*(\\d+)', response_text)\n",
        "\n",
        "            # If we have a final score, use that\n",
        "            if final_match:\n",
        "                score = int(final_match.group(1))\n",
        "                return min(10, max(1, score))  # Ensure score is between 1 and 10\n",
        "\n",
        "            # If we have both coherence and distinctiveness, calculate average\n",
        "            if coherence_match and distinctiveness_match:\n",
        "                coherence_score = float(coherence_match.group(1))\n",
        "                distinctiveness_score = float(distinctiveness_match.group(1))\n",
        "                return round((coherence_score + distinctiveness_score) / 2)\n",
        "\n",
        "            # Try other numerical patterns\n",
        "            score_patterns = [\n",
        "                r'score[^0-9]*(\\d+)',\n",
        "                r'rated[^0-9]*(\\d+)',\n",
        "                r'(\\d+)[^0-9]*out of[^0-9]*10',\n",
        "                r'(\\d+)[^0-9]*points'\n",
        "            ]\n",
        "\n",
        "            for pattern in score_patterns:\n",
        "                match = re.search(pattern, response_text.lower())\n",
        "                if match:\n",
        "                    score = int(match.group(1))\n",
        "                    if 0 <= score <= 10:\n",
        "                        return score\n",
        "                    elif 0 <= score <= 100:\n",
        "                        return round(score / 10)\n",
        "\n",
        "            # If no numerical score found, use keyword analysis\n",
        "            keywords = {\n",
        "                10: ['exceptional', 'perfect', 'outstanding', 'excellent'],\n",
        "                9: ['very strong', 'highly coherent', 'nearly perfect'],\n",
        "                8: ['strong', 'very good', 'highly relevant'],\n",
        "                7: ['good', 'quite coherent', 'mostly relevant'],\n",
        "                6: ['above average', 'moderately good', 'fairly coherent'],\n",
        "                5: ['average', 'moderate', 'mixed'],\n",
        "                4: ['below average', 'somewhat weak', 'partially relevant'],\n",
        "                3: ['weak', 'poor coherence', 'limited relevance'],\n",
        "                2: ['very weak', 'poor', 'minimal coherence'],\n",
        "                1: ['incoherent', 'irrelevant', 'completely disconnected']\n",
        "            }\n",
        "\n",
        "            response_lower = response_text.lower()\n",
        "            for score, terms in keywords.items():\n",
        "                if any(term in response_lower for term in terms):\n",
        "                    return score\n",
        "\n",
        "            # Count positive and negative indicators\n",
        "            positive_indicators = sum(term in response_lower for term in\n",
        "                ['consistent', 'coherent', 'well', 'clear', 'strong', 'good'])\n",
        "            negative_indicators = sum(term in response_lower for term in\n",
        "                ['inconsistent', 'weak', 'poor', 'lacks', 'missing', 'limited'])\n",
        "\n",
        "            if positive_indicators or negative_indicators:\n",
        "                base_score = 5\n",
        "                score_modifier = positive_indicators - negative_indicators\n",
        "                return min(10, max(1, base_score + score_modifier))\n",
        "\n",
        "            return 5  # Default middle score if no other indicators found\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting score: {e}\")\n",
        "            return 5\n",
        "\n",
        "    def _extract_topic_info(self, response_text):\n",
        "        \"\"\"Extract topic information from response\"\"\"\n",
        "        try:\n",
        "            return {\n",
        "                \"primary_topic\": find_pattern_safely(r'PRIMARY_TOPIC:\\s*([^\\n]+)', response_text, \"unknown\"),\n",
        "                \"subtopics\": find_pattern_safely(r'SUBTOPICS:\\s*([^\\n]+)', response_text, \"\").split(','),\n",
        "                \"technical_indicators\": find_pattern_safely(r'TECHNICAL_INDICATORS:\\s*([^\\n]+)', response_text, \"\").split(','),\n",
        "                \"cross_domain\": find_pattern_safely(r'CROSS_DOMAIN_ELEMENTS:\\s*([^\\n]+)', response_text, \"\").split(','),\n",
        "                \"confidence\": float(find_pattern_safely(r'CONFIDENCE:\\s*(0\\.\\d+|1\\.0)', response_text, \"0.5\"))\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting topic info: {e}\")\n",
        "            return {\n",
        "                \"primary_topic\": \"unknown\",\n",
        "                \"subtopics\": [],\n",
        "                \"technical_indicators\": [],\n",
        "                \"cross_domain\": [],\n",
        "                \"confidence\": 0.5\n",
        "            }\n",
        "\n",
        "    def _calculate_group_coherence(self, documents):\n",
        "        \"\"\"Calculate internal coherence of a group of documents\"\"\"\n",
        "        try:\n",
        "            processed_docs = preprocess_documents(documents)\n",
        "            dictionary = Dictionary(processed_docs)\n",
        "            coherence_scores = calculate_coherence_scores([processed_docs], dictionary)\n",
        "            return coherence_scores[0] if coherence_scores else 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating group coherence: {e}\")\n",
        "            return 0.0\n"
      ],
      "metadata": {
        "id": "sVfRW8aa-8m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coherence score calculation with error handling and normalization"
      ],
      "metadata": {
        "id": "HrSIfCxdGOxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_coherence_scores(groups, dictionary, measure=\"c_v\"):\n",
        "    scores = []\n",
        "    for group in groups:\n",
        "        try:\n",
        "            # Create \"topics\" as a list of the most frequent terms in the group\n",
        "            topics = [[word for word, freq in dictionary.doc2bow(doc)] for doc in group]\n",
        "\n",
        "            # Create a CoherenceModel for the group\n",
        "            coherence_model = CoherenceModel(\n",
        "                topics=topics,\n",
        "                texts=group,\n",
        "                dictionary=dictionary,\n",
        "                coherence=measure\n",
        "            )\n",
        "\n",
        "            # Calculate the coherence score\n",
        "            score = coherence_model.get_coherence()\n",
        "            scores.append(score)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating coherence for group: {e}\")\n",
        "            scores.append(0.0)\n",
        "\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "PB9y7vXEAMhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform LDA analysis with preprocessing"
      ],
      "metadata": {
        "id": "7I0NtQIDGgKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_lda_analysis(documents, n_topics=5):\n",
        "    if not documents or not isinstance(documents, list):\n",
        "        return {\"assigned_topics\": [], \"topics_keywords\": {}}\n",
        "\n",
        "    try:\n",
        "        vectorizer = CountVectorizer(\n",
        "            stop_words='english',\n",
        "            max_df=0.95,\n",
        "            min_df=2,\n",
        "            token_pattern=r'(?u)\\b\\w+\\b'\n",
        "        )\n",
        "\n",
        "        X = vectorizer.fit_transform(documents)\n",
        "\n",
        "        lda_model = LatentDirichletAllocation(\n",
        "            n_components=n_topics,\n",
        "            random_state=42,\n",
        "            max_iter=20,\n",
        "            learning_method='batch'\n",
        "        )\n",
        "\n",
        "        lda_model.fit(X)\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "        topics = {}\n",
        "        for topic_idx, topic in enumerate(lda_model.components_):\n",
        "            top_keywords_idx = topic.argsort()[-10:][::-1]\n",
        "            top_keywords = [feature_names[i] for i in top_keywords_idx]\n",
        "            topics[topic_idx] = top_keywords\n",
        "\n",
        "        topic_assignments = lda_model.transform(X)\n",
        "        assigned_topics = np.argmax(topic_assignments, axis=1)\n",
        "\n",
        "        return {\n",
        "            \"assigned_topics\": assigned_topics.tolist(),\n",
        "            \"topics_keywords\": topics\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in LDA analysis: {str(e)}\")\n",
        "        return {\"assigned_topics\": [], \"topics_keywords\": {}}"
      ],
      "metadata": {
        "id": "cNagldOtGZn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic assignment with error handling\n"
      ],
      "metadata": {
        "id": "ik1follNHHAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_topic_to_group(documents, n_topics=5):\n",
        "    # Get LDA topics\n",
        "    lda_results = perform_lda_analysis(documents, n_topics)\n",
        "\n",
        "    # Get LLM topic analysis\n",
        "    llm_topics = set()  # Use set for automatic deduplication\n",
        "    try:\n",
        "        for doc in documents:\n",
        "            response = llm_processor.process_text(doc, \"topic\")\n",
        "            if response and not response.error and response.content:\n",
        "                # Extract topics with fallbacks\n",
        "                primary = find_pattern_safely(r'PRIMARY_TOPIC:\\s*([^\\n]+)', response.content)\n",
        "                subtopics = find_pattern_safely(r'SUBTOPICS:\\s*([^\\n]+)', response.content)\n",
        "                tech_indicators = find_pattern_safely(r'TECHNICAL_INDICATORS:\\s*([^\\n]+)', response.content)\n",
        "                cross_domain = find_pattern_safely(r'CROSS_DOMAIN_ELEMENTS:\\s*([^\\n]+)', response.content)\n",
        "\n",
        "                # Process primary topic\n",
        "                if primary:\n",
        "                    clean_primary = clean_topic(primary)\n",
        "                    if clean_primary:\n",
        "                        llm_topics.add(clean_primary)\n",
        "\n",
        "                # Process subtopics\n",
        "                if subtopics:\n",
        "                    for topic in subtopics.split(','):\n",
        "                        clean_sub = clean_topic(topic)\n",
        "                        if clean_sub:\n",
        "                            llm_topics.add(clean_sub)\n",
        "\n",
        "                # Process technical indicators\n",
        "                if tech_indicators:\n",
        "                    for term in tech_indicators.split(','):\n",
        "                        clean_term = clean_topic(term)\n",
        "                        if clean_term and len(clean_term.split()) > 1:  # Only add multi-word technical terms\n",
        "                            llm_topics.add(clean_term)\n",
        "\n",
        "                # Process cross-domain elements\n",
        "                if cross_domain:\n",
        "                    for element in cross_domain.split(','):\n",
        "                        clean_element = clean_topic(element)\n",
        "                        if clean_element:\n",
        "                            llm_topics.add(clean_element)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in LLM topic analysis: {str(e)}\")\n",
        "\n",
        "    # Convert set to sorted list for consistent output\n",
        "    llm_topics_list = sorted(list(llm_topics))\n",
        "\n",
        "    # Group similar topics\n",
        "    grouped_topics = []\n",
        "    processed = set()\n",
        "\n",
        "    for topic in llm_topics_list:\n",
        "        if topic in processed:\n",
        "            continue\n",
        "\n",
        "        similar_topics = [topic]\n",
        "        processed.add(topic)\n",
        "\n",
        "        # Find similar topics\n",
        "        for other in llm_topics_list:\n",
        "            if other not in processed:\n",
        "                # Check if topics are very similar\n",
        "                if (topic.lower() in other.lower() or\n",
        "                    other.lower() in topic.lower() or\n",
        "                    len(set(topic.lower().split()) & set(other.lower().split())) >= 2):\n",
        "                    similar_topics.append(other)\n",
        "                    processed.add(other)\n",
        "\n",
        "        # Add the main topic or the shortest similar topic\n",
        "        if len(similar_topics) > 1:\n",
        "            grouped_topics.append(min(similar_topics, key=len))\n",
        "        else:\n",
        "            grouped_topics.append(topic)\n",
        "\n",
        "    result = {\n",
        "        \"lda_results\": lda_results,\n",
        "        \"llm_topics\": grouped_topics,\n",
        "        \"combined_analysis\": {\n",
        "            \"assigned_topics\": lda_results[\"assigned_topics\"],\n",
        "            \"topics_keywords\": lda_results[\"topics_keywords\"],\n",
        "            \"llm_suggested_topics\": grouped_topics\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "Hopk1AP3HEWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get a balanced dataset with specified number of documents per category."
      ],
      "metadata": {
        "id": "E9B8WQxTHjZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_balanced_dataset(newsgroups, category_groups, docs_per_category=3):\n",
        "\n",
        "    group_docs = []\n",
        "    category_counts = {}\n",
        "\n",
        "    for group_categories in category_groups:\n",
        "        group_data = []\n",
        "        group_total = 0\n",
        "\n",
        "        for category in group_categories:\n",
        "            category_indices = [i for i in range(len(newsgroups.target))\n",
        "                              if newsgroups.target_names[newsgroups.target[i]] == category]\n",
        "\n",
        "            # Get and preprocess documents\n",
        "            category_docs = [preprocess_text(newsgroups.data[i])\n",
        "                           for i in category_indices[:docs_per_category]]\n",
        "            group_data.extend(category_docs)\n",
        "\n",
        "            category_counts[category] = len(category_docs)\n",
        "            group_total += len(category_docs)\n",
        "\n",
        "        group_docs.append(group_data)\n",
        "\n",
        "        print(f\"\\nGroup with categories {group_categories}:\")\n",
        "        print(f\"Total documents: {group_total}\")\n",
        "        for category in group_categories:\n",
        "            print(f\"  - {category}: {category_counts[category]} documents\")\n",
        "\n",
        "    return group_docs, category_counts\n",
        "\n"
      ],
      "metadata": {
        "id": "-No1ypbMHiOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate groups multiple times"
      ],
      "metadata": {
        "id": "xDoXDxcWHvf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_multiple_times(group1, group2, group3, topics=None, num_iterations=3):\n",
        "\n",
        "    if topics is None:\n",
        "        topics = ['Technology', 'Scientific', 'Social/Political']\n",
        "\n",
        "    scores = {\n",
        "        'llm_scores': {topic: [] for topic in topics},\n",
        "        'coherence_scores': {topic: [] for topic in topics}\n",
        "    }\n",
        "\n",
        "    print(\"Summarizing documents...\")\n",
        "    summarized_group1 = [llm_processor.process_text(doc, \"summarize\").content for doc in group1]\n",
        "    summarized_group2 = [llm_processor.process_text(doc, \"summarize\").content for doc in group2]\n",
        "    summarized_group3 = [llm_processor.process_text(doc, \"summarize\").content for doc in group3]\n",
        "\n",
        "    # Preprocess all groups once\n",
        "    all_groups = [group1, group2, group3]\n",
        "    tokenized_groups = [preprocess_documents(group) for group in all_groups]\n",
        "\n",
        "    # Create dictionary from all documents\n",
        "    all_docs_tokenized = [token for group in tokenized_groups for token in group]\n",
        "    dictionary = Dictionary(all_docs_tokenized)\n",
        "    dictionary.filter_extremes(no_below=2, no_above=0.95)  # Filter extreme terms\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        print(f\"\\nIteration {i + 1}/{num_iterations}\")\n",
        "        print(\"Performing LLM evaluation...\")\n",
        "\n",
        "        for j, (group, topic) in enumerate(zip([summarized_group1, summarized_group2, summarized_group3], topics)):\n",
        "            other_groups = [g for k, g in enumerate([summarized_group1, summarized_group2, summarized_group3]) if k != j]\n",
        "            scores['llm_scores'][topic].append(\n",
        "                llm_processor.process_text(\"\", \"grade\", {\n",
        "                    \"documents\": \"\\n\".join(group),\n",
        "                    \"other_groups\": \"\\n\".join([\"\\n\".join(g) for g in other_groups])\n",
        "                }).score\n",
        "            )\n",
        "\n",
        "    print(\"Calculating coherence scores...\")\n",
        "    coherence_scores = calculate_coherence_scores(tokenized_groups, dictionary)\n",
        "    for topic, score in zip(topics, coherence_scores):\n",
        "        scores['coherence_scores'][topic] = [score]  # Single coherence score per group\n",
        "\n",
        "    # Calculate results\n",
        "    results = {}\n",
        "    for score_type in ['llm_scores', 'coherence_scores']:\n",
        "        results[score_type] = {\n",
        "            'scores': scores[score_type],\n",
        "            'avg': {topic: sum(topic_scores)/len(topic_scores)\n",
        "                   for topic, topic_scores in scores[score_type].items()},\n",
        "            'std': {topic: ((sum((x - sum(topic_scores)/len(topic_scores)) ** 2\n",
        "                   for x in topic_scores) / len(topic_scores)) ** 0.5)\n",
        "                   for topic, topic_scores in scores[score_type].items()}\n",
        "        }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "0zg2lZbKHund"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run experiment"
      ],
      "metadata": {
        "id": "o8NRGsiJH-SP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlIeHzqT-V5I",
        "outputId": "9890288f-7a79-45ed-9a35-a030782941c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "\n",
            "Getting balanced dataset...\n",
            "\n",
            "Group with categories ['comp.graphics']:\n",
            "Total documents: 5\n",
            "  - comp.graphics: 5 documents\n",
            "\n",
            "Group with categories ['sci.space']:\n",
            "Total documents: 5\n",
            "  - sci.space: 5 documents\n",
            "\n",
            "Getting unbalanced dataset...\n",
            "\n",
            "Group with categories ['sci.space']:\n",
            "Total documents: 1\n",
            "  - sci.space: 1 documents\n",
            "\n",
            "Group with categories ['sci.electronics']:\n",
            "Total documents: 1\n",
            "  - sci.electronics: 1 documents\n",
            "\n",
            "Group with categories ['rec.autos']:\n",
            "Total documents: 1\n",
            "  - rec.autos: 1 documents\n",
            "\n",
            "Group with categories ['soc.religion.christian']:\n",
            "Total documents: 1\n",
            "  - soc.religion.christian: 1 documents\n",
            "\n",
            "Group with categories ['talk.politics.mideast']:\n",
            "Total documents: 1\n",
            "  - talk.politics.mideast: 1 documents\n",
            "\n",
            "Initializing RAG system...\n",
            "\n",
            "Analyzing topics for each group...\n",
            "\n",
            "Group 1 (Graphics) Topics:\n",
            "{'lda_results': {'assigned_topics': [0, 4, 2, 4, 0], 'topics_keywords': {0: ['international', 'features', 'geometric', 'description', 'using', 'form'], 1: ['using', 'form', 'geometric', 'description', 'features', 'international'], 2: ['form', 'geometric', 'using', 'description', 'features', 'international'], 3: ['using', 'form', 'geometric', 'description', 'features', 'international'], 4: ['using', 'description', 'form', 'geometric', 'features', 'international']}}, 'llm_topics': ['3D Graphics', '3D Modeling & Rendering', 'CAD/CAE Systems', 'Computer Graphics', 'Computer Systems', 'Computer-Generated Imagery (CGI', 'Engineering (Mechanical Engineering', 'Geometric Computing or Computational Geometry', 'Geometric Modeling', 'Geometric objects', 'Graphics Rendering', 'None', 'Polytope Theory', 'Silicon Graphics', 'Software Development', 'VESA (Video Electronics Standards Association', 'Variational Geometry'], 'combined_analysis': {'assigned_topics': [0, 4, 2, 4, 0], 'topics_keywords': {0: ['international', 'features', 'geometric', 'description', 'using', 'form'], 1: ['using', 'form', 'geometric', 'description', 'features', 'international'], 2: ['form', 'geometric', 'using', 'description', 'features', 'international'], 3: ['using', 'form', 'geometric', 'description', 'features', 'international'], 4: ['using', 'description', 'form', 'geometric', 'features', 'international']}, 'llm_suggested_topics': ['3D Graphics', '3D Modeling & Rendering', 'CAD/CAE Systems', 'Computer Graphics', 'Computer Systems', 'Computer-Generated Imagery (CGI', 'Engineering (Mechanical Engineering', 'Geometric Computing or Computational Geometry', 'Geometric Modeling', 'Geometric objects', 'Graphics Rendering', 'None', 'Polytope Theory', 'Silicon Graphics', 'Software Development', 'VESA (Video Electronics Standards Association', 'Variational Geometry']}}\n",
            "\n",
            "Group 2 (Space) Topics:\n",
            "{'lda_results': {'assigned_topics': [2, 1, 0, 4, 4], 'topics_keywords': {0: ['nasa', 'make', 'general', 'dynamics', 'early', 'flight', 'teams', 'research', 'using', 'space'], 1: ['question', 'awst', 'lunar', 'manned', 'general', 'dynamics', 'early', 'flight', 'make', 'teams'], 2: ['awst', 'lunar', 'manned', 'question', 'general', 'dynamics', 'early', 'flight', 'make', 'teams'], 3: ['question', 'awst', 'lunar', 'manned', 'general', 'dynamics', 'early', 'flight', 'make', 'teams'], 4: ['cost', 'space', 'article', 'low', 'shuttle', 'manned', 'got', 'wrote', 'titan', 'unmanned']}}, 'llm_topics': ['AIAA (American Institute of Aeronautics & Astronautics', 'Aerodynamics', 'Aerospace Engineering', 'Aerospace Industry Management', 'FAQs', 'Help Desk', 'Historical context (WWII', 'Information Technology', 'NACA', 'NASA', 'None', 'Space Exploration', 'Space Station Redesign', 'Sweep wings', 'Technical Support', 'Titan Shuttle', 'Troubleshooting', 'WWII-era aircraft'], 'combined_analysis': {'assigned_topics': [2, 1, 0, 4, 4], 'topics_keywords': {0: ['nasa', 'make', 'general', 'dynamics', 'early', 'flight', 'teams', 'research', 'using', 'space'], 1: ['question', 'awst', 'lunar', 'manned', 'general', 'dynamics', 'early', 'flight', 'make', 'teams'], 2: ['awst', 'lunar', 'manned', 'question', 'general', 'dynamics', 'early', 'flight', 'make', 'teams'], 3: ['question', 'awst', 'lunar', 'manned', 'general', 'dynamics', 'early', 'flight', 'make', 'teams'], 4: ['cost', 'space', 'article', 'low', 'shuttle', 'manned', 'got', 'wrote', 'titan', 'unmanned']}, 'llm_suggested_topics': ['AIAA (American Institute of Aeronautics & Astronautics', 'Aerodynamics', 'Aerospace Engineering', 'Aerospace Industry Management', 'FAQs', 'Help Desk', 'Historical context (WWII', 'Information Technology', 'NACA', 'NASA', 'None', 'Space Exploration', 'Space Station Redesign', 'Sweep wings', 'Technical Support', 'Titan Shuttle', 'Troubleshooting', 'WWII-era aircraft']}}\n",
            "\n",
            "Group 3 (Mixed) Topics:\n",
            "{'lda_results': {'assigned_topics': [2, 0, 0, 3, 2], 'topics_keywords': {0: ['time', 'new', 'usa', 'says', 'really', 'know'], 1: ['know', 'says', 'really', 'usa', 'time', 'new'], 2: ['know', 'usa', 'time', 'new', 'says', 'really'], 3: ['says', 'really', 'know', 'usa', 'time', 'new'], 4: ['know', 'says', 'really', 'usa', 'time', 'new']}}, 'llm_topics': ['1 millisecond refresh rates', '4x4 extended cab', 'AIAA (American Institute of Aeronautics & Astronautics', 'Aerospace Engineering', 'Automotive Engineering', 'Azeris', 'Church Administration', 'Conference/meeting (interdisciplinary aspect', 'Conflict Resolution/International Law', 'Consumer reviews & opinions', 'Display Technology', 'Evangelical Theology', 'Experimental Psychology', 'Geneva Convention', 'Human Factors Engineering', 'Human Rights', 'Kurds', 'Lutheran Church', 'None', 'Politics/Ethnicity (Armenians', 'Space Exploration', 'Turks', 'Vectortype displays', 'Vehicle Performance & Reliability', 'Visual Perception', 'combining technical & social aspects'], 'combined_analysis': {'assigned_topics': [2, 0, 0, 3, 2], 'topics_keywords': {0: ['time', 'new', 'usa', 'says', 'really', 'know'], 1: ['know', 'says', 'really', 'usa', 'time', 'new'], 2: ['know', 'usa', 'time', 'new', 'says', 'really'], 3: ['says', 'really', 'know', 'usa', 'time', 'new'], 4: ['know', 'says', 'really', 'usa', 'time', 'new']}, 'llm_suggested_topics': ['1 millisecond refresh rates', '4x4 extended cab', 'AIAA (American Institute of Aeronautics & Astronautics', 'Aerospace Engineering', 'Automotive Engineering', 'Azeris', 'Church Administration', 'Conference/meeting (interdisciplinary aspect', 'Conflict Resolution/International Law', 'Consumer reviews & opinions', 'Display Technology', 'Evangelical Theology', 'Experimental Psychology', 'Geneva Convention', 'Human Factors Engineering', 'Human Rights', 'Kurds', 'Lutheran Church', 'None', 'Politics/Ethnicity (Armenians', 'Space Exploration', 'Turks', 'Vectortype displays', 'Vehicle Performance & Reliability', 'Visual Perception', 'combining technical & social aspects']}}\n",
            "\n",
            "Performing multiple evaluations...\n",
            "Summarizing documents...\n",
            "\n",
            "Iteration 1/5\n",
            "Performing LLM evaluation...\n",
            "\n",
            "Iteration 2/5\n",
            "Performing LLM evaluation...\n",
            "\n",
            "Iteration 3/5\n",
            "Performing LLM evaluation...\n",
            "\n",
            "Iteration 4/5\n",
            "Performing LLM evaluation...\n",
            "\n",
            "Iteration 5/5\n",
            "Performing LLM evaluation...\n",
            "Calculating coherence scores...\n",
            "\n",
            "Evaluation Results:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "LLM Scores (1-10):\n",
            "\n",
            "graphics:\n",
            "  Average Score: 8.00\n",
            "  Standard Deviation: 0.00\n",
            "  All Scores: [8, 8, 8, 8, 8]\n",
            "\n",
            "space:\n",
            "  Average Score: 7.60\n",
            "  Standard Deviation: 0.49\n",
            "  All Scores: [8, 7, 8, 7, 8]\n",
            "\n",
            "Political:\n",
            "  Average Score: 7.40\n",
            "  Standard Deviation: 0.49\n",
            "  All Scores: [8, 8, 7, 7, 7]\n",
            "\n",
            "Coherence Scores:\n",
            "\n",
            "graphics:\n",
            "  Score: 0.77\n",
            "  Standard Deviation: 0.00\n",
            "  All Scores: [0.7720446082842288]\n",
            "\n",
            "space:\n",
            "  Score: 0.72\n",
            "  Standard Deviation: 0.00\n",
            "  All Scores: [0.721565326659365]\n",
            "\n",
            "Political:\n",
            "  Score: 0.74\n",
            "  Standard Deviation: 0.00\n",
            "  All Scores: [0.7445648956560619]\n",
            "\n",
            "Analysis complete!\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize API key\n",
        "    api_key = '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'\n",
        "    client = Groq(api_key=api_key)\n",
        "\n",
        "    # Initialize processors\n",
        "    llm_processor = EnhancedLLMProcessor(api_key)\n",
        "    rag_system = RAGSystem()\n",
        "\n",
        "    # Load the 20 newsgroups dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    # Define the groups for analysis\n",
        "    topics = ['graphics', 'space', 'Political']\n",
        "\n",
        "    group_categories = [\n",
        "        ['comp.graphics'],\n",
        "        ['sci.space']\n",
        "    ]\n",
        "\n",
        "    group2_categories = [\n",
        "        ['sci.space'],\n",
        "        ['sci.electronics'],\n",
        "        ['rec.autos'],\n",
        "        ['soc.religion.christian'],\n",
        "        ['talk.politics.mideast']\n",
        "    ]\n",
        "\n",
        "    # Get balanced dataset\n",
        "    print(\"\\nGetting balanced dataset...\")\n",
        "    balanced_groups, category_counts = get_balanced_dataset(newsgroups, group_categories, docs_per_category=5)\n",
        "    group1, group2 = balanced_groups\n",
        "\n",
        "    # Get unbalanced group\n",
        "    print(\"\\nGetting unbalanced dataset...\")\n",
        "    unbalanced_group = get_balanced_dataset(newsgroups, group2_categories, docs_per_category=1)\n",
        "    group3 = unbalanced_group[0]\n",
        "    group3 = [string for sublist in group3 for string in sublist]\n",
        "\n",
        "    # Initialize RAG system\n",
        "    print(\"\\nInitializing RAG system...\")\n",
        "    all_docs = group1 + group2 + group3\n",
        "    rag_system.add_documents(all_docs)\n",
        "\n",
        "    # Perform topic analysis\n",
        "    print(\"\\nAnalyzing topics for each group...\")\n",
        "    print(\"\\nGroup 1 (Graphics) Topics:\")\n",
        "    print(assign_topic_to_group(group1))\n",
        "    print(\"\\nGroup 2 (Space) Topics:\")\n",
        "    print(assign_topic_to_group(group2))\n",
        "    print(\"\\nGroup 3 (Mixed) Topics:\")\n",
        "    print(assign_topic_to_group(group3))\n",
        "\n",
        "    # Perform multiple evaluations\n",
        "    print(\"\\nPerforming multiple evaluations...\")\n",
        "    results = evaluate_multiple_times(group1, group2, group3, topics=topics, num_iterations=5)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    print(\"\\nLLM Scores (1-10):\")\n",
        "    for topic in topics:\n",
        "        print(f\"\\n{topic}:\")\n",
        "        print(f\"  Average Score: {results['llm_scores']['avg'][topic]:.2f}\")\n",
        "        print(f\"  Standard Deviation: {results['llm_scores']['std'][topic]:.2f}\")\n",
        "        print(f\"  All Scores: {results['llm_scores']['scores'][topic]}\")\n",
        "\n",
        "    print(\"\\nCoherence Scores:\")\n",
        "    for topic in topics:\n",
        "        print(f\"\\n{topic}:\")\n",
        "        print(f\"  Score: {results['coherence_scores']['avg'][topic]:.2f}\")\n",
        "        print(f\"  Standard Deviation: {results['coherence_scores']['std'][topic]:.2f}\")\n",
        "        if topic in results['coherence_scores']['scores']:\n",
        "            print(f\"  All Scores: {results['coherence_scores']['scores'][topic]}\")\n",
        "\n",
        "    print(\"\\nAnalysis complete!\")"
      ]
    }
  ]
}